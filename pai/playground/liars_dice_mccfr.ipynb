{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2),\n",
       " (1, 3),\n",
       " (1, 4),\n",
       " (1, 5),\n",
       " (1, 6),\n",
       " (2, 1),\n",
       " (2, 2),\n",
       " (2, 3),\n",
       " (2, 4),\n",
       " (2, 5),\n",
       " (2, 6),\n",
       " 'LIAR']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_DICE = 1\n",
    "MAX_DICE_FACE = 6\n",
    "\n",
    "action_to_index = {}\n",
    "index_to_action = {}\n",
    "\n",
    "# Generate action map.\n",
    "index = 0\n",
    "for dice_num in range(1, 2 * NUM_DICE + 1):\n",
    "    for face in range(1, MAX_DICE_FACE + 1):\n",
    "        action = (dice_num, face)\n",
    "        action_to_index[action] = index\n",
    "        index_to_action[index] = action\n",
    "        index += 1\n",
    "\n",
    "action_to_index[\"LIAR\"] = index\n",
    "index_to_action[index] = \"LIAR\"\n",
    "non_liar_actions = []\n",
    "\n",
    "for action in action_to_index.keys():\n",
    "    if action != \"LIAR\":\n",
    "        non_liar_actions.append(action)\n",
    "\n",
    "non_liar_actions = sorted(non_liar_actions)\n",
    "\n",
    "NUM_ACTIONS = len(action_to_index)\n",
    "\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def allowed_actions(last_bet):\n",
    "    if last_bet == None:\n",
    "        return non_liar_actions\n",
    "\n",
    "    if last_bet == \"LIAR\":\n",
    "        return []\n",
    "\n",
    "    last_num, last_face = last_bet\n",
    "\n",
    "    # Can either increase number of dice or change the face.\n",
    "    actions = []\n",
    "\n",
    "    for action in non_liar_actions:\n",
    "        action_num, action_face = action\n",
    "\n",
    "        if action_face > last_face:\n",
    "            actions.append(action)\n",
    "            continue\n",
    "\n",
    "        if action_num > last_num and action_face == last_face:\n",
    "            actions.append(action)\n",
    "            continue\n",
    "\n",
    "    actions.append(\"LIAR\")\n",
    "\n",
    "    return actions\n",
    "\n",
    "allowed_actions((1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:27<00:00, 367.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average game value: -0.056913270449756866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def sample_action(strategy, valid_actions):\n",
    "    return valid_actions[np.random.choice(list(range(len(valid_actions))), p=strategy)]\n",
    "\n",
    "class Node(object):\n",
    "    \"\"\"Store the current game state.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, deciding_player=-1, history=None, deal=False, player_dice=None):\n",
    "        self._history = history if history is not None else []\n",
    "        self._player_dice = player_dice\n",
    "        self._deciding_player = deciding_player\n",
    "        self._deal = deal\n",
    "\n",
    "    @property\n",
    "    def deciding_player_dice(self):\n",
    "        return self._player_dice[self._deciding_player]\n",
    "\n",
    "    @property\n",
    "    def deciding_player(self):\n",
    "        return self._deciding_player\n",
    "\n",
    "    @property\n",
    "    def chance_node(self):\n",
    "        return self._deal\n",
    "\n",
    "    @property\n",
    "    def history(self):\n",
    "        return self._history\n",
    "\n",
    "    def sample_chance(self):\n",
    "        assert self.chance_node\n",
    "        player_dice = np.random.randint(1, MAX_DICE_FACE + 1, size=(2, NUM_DICE)).tolist()\n",
    "        player_dice = tuple([tuple(sorted(dice)) for dice in player_dice])\n",
    "\n",
    "        return Node(\n",
    "            deciding_player=0,\n",
    "            history=[],\n",
    "            deal=False,\n",
    "            player_dice=player_dice,\n",
    "        )\n",
    "\n",
    "    def terminal(self, perspective_player):\n",
    "        \"\"\"Return (is_terminal, utility).\n",
    "        \"\"\"\n",
    "\n",
    "        if len(self._history) == 0:\n",
    "            return False, None\n",
    "\n",
    "        if len(self._history) > 20:\n",
    "            return True, 0\n",
    "\n",
    "        if self._history[-1] == \"LIAR\":\n",
    "            # Terminal.\n",
    "            # Find out who one.\n",
    "            bet_in_question = self._history[-2]\n",
    "            bet_num, bet_face = bet_in_question\n",
    "            player_in_question = self._deciding_player\n",
    "\n",
    "            actual_num = 0\n",
    "\n",
    "            for player_index in range(2):\n",
    "                for dice_index in range(NUM_DICE):\n",
    "                    if self._player_dice[player_index][dice_index] == bet_face:\n",
    "                        actual_num += 1\n",
    "\n",
    "            if actual_num >= bet_num:\n",
    "                # Player in question wins.\n",
    "                if player_in_question == perspective_player:\n",
    "                    return True, 1\n",
    "                else:\n",
    "                    return True, -1\n",
    "            else:\n",
    "                # Player in question loses.\n",
    "                if player_in_question == perspective_player:\n",
    "                    return True, -1\n",
    "                else:\n",
    "                    return True, 1\n",
    "\n",
    "        return False, None\n",
    "\n",
    "    def take_action(self, action):\n",
    "        # Assumes action is valid.\n",
    "        assert not self.chance_node\n",
    "        return Node(\n",
    "            deciding_player=1 - self._deciding_player,\n",
    "            history=self._history + [action],\n",
    "            deal=False,\n",
    "            player_dice=self._player_dice,\n",
    "        )\n",
    "\n",
    "class InfoSet(object):\n",
    "    def __init__(self, num_actions):\n",
    "        self.regret_sum = np.zeros(num_actions)\n",
    "        self.strategy = np.zeros(num_actions)\n",
    "        self.strategy_sum = np.zeros(num_actions)\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "    def get_strategy(self):\n",
    "        regret_sum_clipped = np.clip(self.regret_sum, a_min=0, a_max=None)\n",
    "        denom = np.sum(regret_sum_clipped)\n",
    "\n",
    "        if denom < 0.001:\n",
    "            self.strategy = np.ones(self.num_actions) / self.num_actions\n",
    "        else:\n",
    "            self.strategy = regret_sum_clipped / denom\n",
    "\n",
    "        return self.strategy\n",
    "\n",
    "    def get_average_strategy(self):\n",
    "        avg_strategy = np.zeros(self.num_actions)\n",
    "        normalizing_sum = 0\n",
    "        \n",
    "        for a in range(self.num_actions):\n",
    "            normalizing_sum += self.strategy_sum[a]\n",
    "        for a in range(self.num_actions):\n",
    "            if normalizing_sum > 0:\n",
    "                avg_strategy[a] = self.strategy_sum[a] / normalizing_sum\n",
    "            else:\n",
    "                avg_strategy[a] = 1.0 / self.num_actions\n",
    "        \n",
    "        return avg_strategy\n",
    "\n",
    "\n",
    "def mccfr_iteration(node: Node, traversing_player: int, infosets: Dict[int, InfoSet]):\n",
    "    if node.chance_node:\n",
    "        return mccfr_iteration(node.sample_chance(), traversing_player, infosets)\n",
    "\n",
    "    is_terminal, utility = node.terminal(traversing_player)\n",
    "    if is_terminal:\n",
    "        return utility\n",
    "\n",
    "    if len(node.history) == 0:\n",
    "        # First action.\n",
    "        valid_actions = allowed_actions(None)\n",
    "    else:\n",
    "        valid_actions = allowed_actions(node.history[-1])\n",
    "\n",
    "    info_set_key = (node.deciding_player, node.deciding_player_dice, tuple(node.history))\n",
    "    if info_set_key not in infosets:\n",
    "        infosets[info_set_key] = InfoSet(len(valid_actions))\n",
    "    infoset = infosets[info_set_key]\n",
    "\n",
    "    if node.deciding_player == traversing_player:\n",
    "        util = np.zeros(len(valid_actions))\n",
    "        infoset_util = 0\n",
    "        strategy = infoset.get_strategy()\n",
    "\n",
    "        for i, action in enumerate(valid_actions):\n",
    "            next_node = node.take_action(action)\n",
    "            util[i] = mccfr_iteration(next_node, traversing_player, infosets)\n",
    "            infoset_util += strategy[i] * util[i]\n",
    "\n",
    "        regret = util - infoset_util\n",
    "        infoset.regret_sum += regret\n",
    "\n",
    "        return infoset_util\n",
    "\n",
    "    strategy = infoset.get_strategy()\n",
    "    action = sample_action(strategy, valid_actions)\n",
    "    next_node = node.take_action(action)\n",
    "    util = mccfr_iteration(next_node, traversing_player, infosets)\n",
    "    infoset.strategy_sum += strategy\n",
    "    return util\n",
    "\n",
    "def mccfr(iterations):\n",
    "    infosets = {}\n",
    "\n",
    "    util = np.zeros(NUM_ACTIONS)\n",
    "    for t in tqdm.trange(1, iterations + 1): \n",
    "        for traversing_player in range(2):\n",
    "            node = Node(deal=True)\n",
    "            util[traversing_player] += mccfr_iteration(node, traversing_player, infosets)\n",
    "\n",
    "    print('Average game value: {}'.format(util[0]/(iterations)))\n",
    "    return infosets\n",
    "\n",
    "infosets = mccfr(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your dice are: (1,)\n",
      "User move (1, 1)\n",
      "Bot move (1, 4)\n",
      "Invalid move: . Try again.\n",
      "User move LIAR\n",
      "((1,), (4,))\n",
      "End game -1\n"
     ]
    }
   ],
   "source": [
    "root_chance_node = Node(deal=True)\n",
    "current_node = root_chance_node.sample_chance()\n",
    "print(\"Your dice are: {}\".format(current_node.deciding_player_dice))\n",
    "\n",
    "while True:\n",
    "    valid_actions = allowed_actions(current_node.history[-1] if len(current_node.history) else None)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            raw_user_move = input(\"Enter your move: \")\n",
    "            if \"liar\" in raw_user_move.lower():\n",
    "                user_move = \"LIAR\"\n",
    "            else:\n",
    "                user_move = (int(raw_user_move.split(\" \")[0]), int(raw_user_move.split(\" \")[1]))\n",
    "\n",
    "            if user_move not in valid_actions:\n",
    "                print(\"%s is not a valid move.\" % user_move)\n",
    "                continue\n",
    "\n",
    "            break\n",
    "        except:\n",
    "            print(\"Invalid move: %s. Try again.\" % raw_user_move)\n",
    "\n",
    "    print(\"User move\", user_move)\n",
    "    current_node = current_node.take_action(user_move)\n",
    "\n",
    "    term, util = current_node.terminal(0)\n",
    "    if term:\n",
    "        print(current_node._player_dice)\n",
    "        print(\"End game\", util)\n",
    "        break\n",
    "\n",
    "    valid_actions = allowed_actions(current_node.history[-1] if len(current_node.history) else None)\n",
    "    bot_strategy = infosets[(current_node.deciding_player, current_node.deciding_player_dice, tuple(current_node.history))].get_average_strategy()\n",
    "    bot_move = sample_action(bot_strategy, valid_actions)\n",
    "    print(\"Bot move\", bot_move)\n",
    "    current_node = current_node.take_action(bot_move)\n",
    "\n",
    "    term, util = current_node.terminal(0)\n",
    "    if term:\n",
    "        print(current_node._player_dice)\n",
    "        print(\"End game\", util)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 9348.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Utility: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def play_against_random():\n",
    "    root_chance_node = Node(deal=True)\n",
    "    current_node = root_chance_node.sample_chance()\n",
    "    turn = \"BOT\"\n",
    "\n",
    "    while True:\n",
    "        term, util = current_node.terminal(0)\n",
    "\n",
    "        if term:\n",
    "            return util\n",
    "\n",
    "        valid_actions = allowed_actions(current_node.history[-1] if len(current_node.history) else None)\n",
    "\n",
    "        if turn == \"BOT\":\n",
    "            k = (current_node.deciding_player, current_node.deciding_player_dice, tuple(current_node.history))\n",
    "            if k in infosets:\n",
    "                bot_strategy = infosets[k].get_average_strategy()\n",
    "            else:\n",
    "                bot_strategy = np.ones(len(valid_actions)) / len(valid_actions)\n",
    "\n",
    "            bot_move = sample_action(bot_strategy, valid_actions)\n",
    "            current_node = current_node.take_action(bot_move)\n",
    "\n",
    "            turn = \"RAND\"\n",
    "        else:\n",
    "            rand_strat = np.ones(len(valid_actions)) / len(valid_actions)\n",
    "            rand_move = sample_action(rand_strat, valid_actions)\n",
    "\n",
    "            current_node = current_node.take_action(rand_move)\n",
    "            turn = \"BOT\"\n",
    "\n",
    "utility_sum = 0\n",
    "games = 10000\n",
    "\n",
    "for _ in tqdm.trange(games):\n",
    "    utility_sum += play_against_random()\n",
    "\n",
    "print(f\"Average Utility: {utility_sum / games:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 277.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average game value: -0.01984133103296207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 10019.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Utility: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "weak_infosets = mccfr(1000)\n",
    "\n",
    "def play_against_weak():\n",
    "    root_chance_node = Node(deal=True)\n",
    "    current_node = root_chance_node.sample_chance()\n",
    "    turn = \"BOT\"\n",
    "\n",
    "    while True:\n",
    "        term, util = current_node.terminal(0)\n",
    "\n",
    "        if term:\n",
    "            return util\n",
    "\n",
    "        valid_actions = allowed_actions(current_node.history[-1] if len(current_node.history) else None)\n",
    "\n",
    "        if turn == \"BOT\":\n",
    "            k = (current_node.deciding_player, current_node.deciding_player_dice, tuple(current_node.history))\n",
    "            if k in infosets:\n",
    "                bot_strategy = infosets[k].get_average_strategy()\n",
    "            else:\n",
    "                bot_strategy = np.ones(len(valid_actions)) / len(valid_actions)\n",
    "\n",
    "            bot_move = sample_action(bot_strategy, valid_actions)\n",
    "            current_node = current_node.take_action(bot_move)\n",
    "\n",
    "            turn = \"RAND\"\n",
    "        else:\n",
    "            k = (current_node.deciding_player, current_node.deciding_player_dice, tuple(current_node.history))\n",
    "            if k in weak_infosets:\n",
    "                bot_strategy = weak_infosets[k].get_average_strategy()\n",
    "            else:\n",
    "                bot_strategy = np.ones(len(valid_actions)) / len(valid_actions)\n",
    "\n",
    "            bot_move = sample_action(bot_strategy, valid_actions)\n",
    "            current_node = current_node.take_action(bot_move)\n",
    "\n",
    "            turn = \"BOT\"\n",
    "\n",
    "utility_sum = 0\n",
    "games = 10000\n",
    "\n",
    "for _ in tqdm.trange(games):\n",
    "    utility_sum += play_against_weak()\n",
    "\n",
    "print(f\"Average Utility: {utility_sum / games:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3052e4e95856f191c70944d34dc8a88b882e97c60324a0ab85812ea24714355"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
