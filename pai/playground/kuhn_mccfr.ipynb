{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average game value: -0.058046546251819646\n",
      "0[0, 1] [9.99981252e-01 1.87476565e-05]\n",
      "0[0] [0.66707662 0.33292338]\n",
      "0[1] [9.99954983e-01 4.50166562e-05]\n",
      "0[] [0.7981129 0.2018871]\n",
      "1[0, 1] [0.45458968 0.54541032]\n",
      "1[0] [9.99846427e-01 1.53572964e-04]\n",
      "1[1] [0.66196807 0.33803193]\n",
      "1[] [9.99567149e-01 4.32851393e-04]\n",
      "2[0, 1] [1.28865979e-04 9.99871134e-01]\n",
      "2[0] [2.99886043e-05 9.99970011e-01]\n",
      "2[1] [1.49943022e-05 9.99985006e-01]\n",
      "2[] [0.35010448 0.64989552]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class Node:\n",
    "\tdef __init__(self, num_actions):\n",
    "\t\tself.regret_sum = np.zeros(num_actions)\n",
    "\t\tself.strategy = np.zeros(num_actions)\n",
    "\t\tself.strategy_sum = np.zeros(num_actions)\n",
    "\t\tself.num_actions = num_actions\n",
    "\n",
    "\tdef get_strategy(self):\n",
    "\t\tnormalizing_sum = 0\n",
    "\t\tfor a in range(self.num_actions):\n",
    "\t\t\tif self.regret_sum[a] > 0:\n",
    "\t\t\t\tself.strategy[a] = self.regret_sum[a]\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.strategy[a] = 0\n",
    "\t\t\tnormalizing_sum += self.strategy[a]\n",
    "\n",
    "\t\tfor a in range(self.num_actions):\n",
    "\t\t\tif normalizing_sum > 0:\n",
    "\t\t\t\tself.strategy[a] /= normalizing_sum\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.strategy[a] = 1.0/self.num_actions\n",
    "\n",
    "\t\treturn self.strategy\n",
    "\n",
    "\tdef get_average_strategy(self):\n",
    "\t\tavg_strategy = np.zeros(self.num_actions)\n",
    "\t\tnormalizing_sum = 0\n",
    "\t\t\n",
    "\t\tfor a in range(self.num_actions):\n",
    "\t\t\tnormalizing_sum += self.strategy_sum[a]\n",
    "\t\tfor a in range(self.num_actions):\n",
    "\t\t\tif normalizing_sum > 0:\n",
    "\t\t\t\tavg_strategy[a] = self.strategy_sum[a] / normalizing_sum\n",
    "\t\t\telse:\n",
    "\t\t\t\tavg_strategy[a] = 1.0 / self.num_actions\n",
    "\t\t\n",
    "\t\treturn avg_strategy\n",
    "\n",
    "class KuhnCFR:\n",
    "\tdef __init__(self, iterations, decksize):\n",
    "\t\tself.nbets = 2\n",
    "\t\tself.iterations = iterations\n",
    "\t\tself.decksize = decksize\n",
    "\t\tself.cards = np.arange(decksize)\n",
    "\t\tself.bet_options = 2\n",
    "\t\tself.nodes = {}\n",
    "\n",
    "\tdef cfr_iterations_external(self):\n",
    "\t\tutil = np.zeros(2)\n",
    "\t\tfor t in range(1, self.iterations + 1): \n",
    "\t\t\tfor i in range(2):\n",
    "\t\t\t\trandom.shuffle(self.cards)\n",
    "\t\t\t\tutil[i] += self.external_cfr(self.cards[:2], [], 2, 0, i, t)\n",
    "\t\t\t\t# print(i, util[i])\n",
    "\t\tprint('Average game value: {}'.format(util[0]/(self.iterations)))\n",
    "\t\tfor i in sorted(self.nodes):\n",
    "\t\t\tprint(i, self.nodes[i].get_average_strategy())\n",
    "\n",
    "\tdef external_cfr(self, cards, history, pot, nodes_touched, traversing_player, t):\n",
    "\t\t# print('THIS IS ITERATION', t)\n",
    "\t\t# print(cards, history, pot)\n",
    "\t\tplays = len(history)\n",
    "\t\tacting_player = plays % 2\n",
    "\t\topponent_player = 1 - acting_player\n",
    "\n",
    "        # Is terminal? Return payoffs.\n",
    "\t\tif plays >= 2:\n",
    "\t\t\tif history[-1] == 0 and history[-2] == 1: #bet fold\n",
    "\t\t\t\tif acting_player == traversing_player:\n",
    "\t\t\t\t\treturn 1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\treturn -1\n",
    "\t\t\tif (history[-1] == 0 and history[-2] == 0) or (history[-1] == 1 and history[-2] == 1): # Check-Check or Bet-Call, go to showdown\n",
    "\t\t\t\tif acting_player == traversing_player:\n",
    "\t\t\t\t\tif cards[acting_player] > cards[opponent_player]:\n",
    "\t\t\t\t\t\treturn pot/2 #profit\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\treturn -pot/2\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tif cards[acting_player] > cards[opponent_player]:\n",
    "\t\t\t\t\t\treturn -pot/2\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\treturn pot/2\n",
    "\n",
    "\t\tinfoset = str(cards[acting_player]) + str(history)\n",
    "\t\tif infoset not in self.nodes:\n",
    "\t\t\tself.nodes[infoset] = Node(self.bet_options)\n",
    "\n",
    "\t\tnodes_touched += 1\n",
    "\n",
    "\t\tif acting_player == traversing_player:\n",
    "\t\t\tutil = np.zeros(self.bet_options) #2 actions\n",
    "\t\t\tnode_util = 0\n",
    "\t\t\tstrategy = self.nodes[infoset].get_strategy()\n",
    "\t\t\tfor a in range(self.bet_options):\n",
    "\t\t\t\tnext_history = history + [a]\n",
    "\t\t\t\tpot += a\n",
    "\t\t\t\tutil[a] = self.external_cfr(cards, next_history, pot, nodes_touched, traversing_player, t)\n",
    "\t\t\t\tnode_util += strategy[a] * util[a]\n",
    "\n",
    "\t\t\tfor a in range(self.bet_options):\n",
    "\t\t\t\tregret = util[a] - node_util\n",
    "\t\t\t\tself.nodes[infoset].regret_sum[a] += regret\n",
    "\t\t\treturn node_util\n",
    "\n",
    "\t\telse: #acting_player != traversing_player\n",
    "\t\t\tstrategy = self.nodes[infoset].get_strategy()\n",
    "\t\t\tutil = 0\n",
    "\t\t\tif random.random() < strategy[0]:\n",
    "\t\t\t\tnext_history = history + [0]\n",
    "\t\t\telse: \n",
    "\t\t\t\tnext_history = history + [1]\n",
    "\t\t\t\tpot += 1\n",
    "\t\t\tutil = self.external_cfr(cards, next_history, pot, nodes_touched, traversing_player, t)\n",
    "\t\t\tfor a in range(self.bet_options):\n",
    "\t\t\t\tself.nodes[infoset].strategy_sum[a] += strategy[a]\n",
    "\t\t\treturn util\n",
    "\n",
    "k = KuhnCFR(100000, 3)\n",
    "k.cfr_iterations_external()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average game value: -0.047773684566606786\n",
      "(0, 0, ()) [0.68582453 0.31417547]\n",
      "(0, 0, (0, 1)) [1. 0.]\n",
      "(0, 1, ()) [9.99790282e-01 2.09717782e-04]\n",
      "(0, 1, (0, 1)) [0.35494489 0.64505511]\n",
      "(0, 2, ()) [0.07216767 0.92783233]\n",
      "(0, 2, (0, 1)) [2.08333333e-04 9.99791667e-01]\n",
      "(1, 0, (0,)) [0.65714453 0.34285547]\n",
      "(1, 0, (1,)) [9.99985071e-01 1.49289383e-05]\n",
      "(1, 1, (0,)) [9.99880067e-01 1.19932838e-04]\n",
      "(1, 1, (1,)) [0.64901079 0.35098921]\n",
      "(1, 2, (0,)) [1.50802268e-04 9.99849198e-01]\n",
      "(1, 2, (1,)) [3.01604536e-05 9.99969840e-01]\n"
     ]
    }
   ],
   "source": [
    "CHECK = 0\n",
    "BET = 1\n",
    "NUM_ACTIONS = 2\n",
    "\n",
    "def sample_action(strategy):\n",
    "    return 0 if random.random() < strategy[0] else 1\n",
    "\n",
    "class Node(object):\n",
    "    \"\"\"Store the current game state.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pot=0, deciding_player=-1, history=None, deal=False, cards=None, total_cards=3):\n",
    "        self._history = history if history is not None else []\n",
    "        self._cards = cards if cards is not None else [None, None]\n",
    "        self._pot = pot\n",
    "        self._deciding_player = deciding_player\n",
    "        self._deal = deal\n",
    "        self._total_cards = total_cards\n",
    "\n",
    "    @property\n",
    "    def deciding_player_cards(self):\n",
    "        return self._cards[self._deciding_player]\n",
    "\n",
    "    @property\n",
    "    def deciding_player(self):\n",
    "        return self._deciding_player\n",
    "\n",
    "    @property\n",
    "    def chance_node(self):\n",
    "        return self._deal\n",
    "\n",
    "    @property\n",
    "    def history(self):\n",
    "        return self._history\n",
    "\n",
    "    def sample_chance(self):\n",
    "        assert self.chance_node\n",
    "        deck = list(range(self._total_cards))\n",
    "        random.shuffle(deck)\n",
    "\n",
    "        return Node(\n",
    "            pot=2,\n",
    "            deciding_player=0,\n",
    "            history=[],\n",
    "            deal=False,\n",
    "            cards=[deck[0], deck[1]],\n",
    "            total_cards=self._total_cards\n",
    "        )\n",
    "\n",
    "    def terminal(self, perspective_player):\n",
    "        \"\"\"Return (is_terminal, utility).\n",
    "        \"\"\"\n",
    "\n",
    "        is_terminal = len(self._history) >= 2\n",
    "\n",
    "        if not is_terminal:\n",
    "            return False, None\n",
    "\n",
    "        if self._history[-1] == 0 and self._history[-2] == 1: #bet fold\n",
    "            if self._deciding_player == perspective_player:\n",
    "                return True, 1\n",
    "            else:\n",
    "                return True, -1\n",
    "        if (self._history[-1] == 0 and self._history[-2] == 0) or (self._history[-1] == 1 and self._history[-2] == 1): #check check or bet call, go to showdown\n",
    "            if self._deciding_player == perspective_player:\n",
    "                if self._cards[self._deciding_player] > self._cards[1 - self._deciding_player]:\n",
    "                    return True, self._pot/2 #profit\n",
    "                else:\n",
    "                    return True, -self._pot/2\n",
    "            else:\n",
    "                if self._cards[self._deciding_player] > self._cards[1 - self._deciding_player]:\n",
    "                    return True, -self._pot/2\n",
    "                else:\n",
    "                    return True, self._pot/2\n",
    "\n",
    "        return False, None\n",
    "\n",
    "    def take_action(self, action):\n",
    "        assert not self.chance_node\n",
    "\n",
    "        new_pot = self._pot + (1 if action == BET else 0)\n",
    "\n",
    "        return Node(\n",
    "            pot=new_pot,\n",
    "            deciding_player=1 - self._deciding_player,\n",
    "            history=self._history + [action],\n",
    "            deal=False,\n",
    "            cards=self._cards,\n",
    "            total_cards=self._total_cards\n",
    "        )\n",
    "\n",
    "\n",
    "class InfoSet(object):\n",
    "    def __init__(self, num_actions):\n",
    "        self.regret_sum = np.zeros(num_actions)\n",
    "        self.strategy = np.zeros(num_actions)\n",
    "        self.strategy_sum = np.zeros(num_actions)\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "    def get_strategy(self):\n",
    "        normalizing_sum = 0\n",
    "        for a in range(self.num_actions):\n",
    "            if self.regret_sum[a] > 0:\n",
    "                self.strategy[a] = self.regret_sum[a]\n",
    "            else:\n",
    "                self.strategy[a] = 0\n",
    "            normalizing_sum += self.strategy[a]\n",
    "\n",
    "        for a in range(self.num_actions):\n",
    "            if normalizing_sum > 0:\n",
    "                self.strategy[a] /= normalizing_sum\n",
    "            else:\n",
    "                self.strategy[a] = 1.0/self.num_actions\n",
    "\n",
    "        return self.strategy\n",
    "\n",
    "    def get_average_strategy(self):\n",
    "        avg_strategy = np.zeros(self.num_actions)\n",
    "        normalizing_sum = 0\n",
    "        \n",
    "        for a in range(self.num_actions):\n",
    "            normalizing_sum += self.strategy_sum[a]\n",
    "        for a in range(self.num_actions):\n",
    "            if normalizing_sum > 0:\n",
    "                avg_strategy[a] = self.strategy_sum[a] / normalizing_sum\n",
    "            else:\n",
    "                avg_strategy[a] = 1.0 / self.num_actions\n",
    "        \n",
    "        return avg_strategy\n",
    "\n",
    "\n",
    "def mccfr_iteration(node: Node, traversing_player: int, infosets: Dict[int, InfoSet]):\n",
    "    if node.chance_node:\n",
    "        return mccfr_iteration(node.sample_chance(), traversing_player, infosets)\n",
    "\n",
    "    is_terminal, utility = node.terminal(traversing_player)\n",
    "    if is_terminal:\n",
    "        return utility\n",
    "\n",
    "    info_set_key = (node.deciding_player, node.deciding_player_cards, tuple(node.history))\n",
    "    if info_set_key not in infosets:\n",
    "        infosets[info_set_key] = InfoSet(NUM_ACTIONS)\n",
    "    infoset = infosets[info_set_key]\n",
    "\n",
    "    if node.deciding_player == traversing_player:\n",
    "        util = np.zeros(NUM_ACTIONS)\n",
    "        infoset_util = 0\n",
    "        strategy = infoset.get_strategy()\n",
    "\n",
    "        for a in range(NUM_ACTIONS):\n",
    "            next_node = node.take_action(a)\n",
    "            util[a] = mccfr_iteration(next_node, traversing_player, infosets)\n",
    "            infoset_util += strategy[a] * util[a]\n",
    "\n",
    "        for a in range(NUM_ACTIONS):\n",
    "            regret = util[a] - infoset_util\n",
    "            infoset.regret_sum[a] += regret\n",
    "\n",
    "        return infoset_util\n",
    "\n",
    "    strategy = infoset.get_strategy()\n",
    "    action = sample_action(strategy)\n",
    "    next_node = node.take_action(action)\n",
    "    util = mccfr_iteration(next_node, traversing_player, infosets)\n",
    "\n",
    "    for a in range(NUM_ACTIONS):\n",
    "        infoset.strategy_sum[a] += strategy[a]\n",
    "\n",
    "    return util\n",
    "\n",
    "def mccfr(iterations):\n",
    "    infosets = {}\n",
    "\n",
    "    util = np.zeros(2)\n",
    "    for t in range(1, iterations + 1): \n",
    "        for traversing_player in range(2):\n",
    "            node = Node(pot=2, deal=True)\n",
    "            util[traversing_player] += mccfr_iteration(node, traversing_player, infosets)\n",
    "\n",
    "    print('Average game value: {}'.format(util[0]/(iterations)))\n",
    "    for i in sorted(infosets.keys()):\n",
    "        print(i, infosets[i].get_average_strategy())\n",
    "\n",
    "    return infosets\n",
    "\n",
    "infosets = mccfr(100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win percentage: 16.20%\n"
     ]
    }
   ],
   "source": [
    "def play_against_random():\n",
    "    root_chance_node = Node(deal=True)\n",
    "    current_node = root_chance_node.sample_chance()\n",
    "    turn = \"BOT\"\n",
    "\n",
    "    while True:\n",
    "        term, util = current_node.terminal(0)\n",
    "\n",
    "        if term:\n",
    "            return util\n",
    "\n",
    "        valid_actions = [0, 1]\n",
    "\n",
    "        if turn == \"BOT\":\n",
    "            k = (current_node.deciding_player, current_node.deciding_player_cards, tuple(current_node.history))\n",
    "            if k in infosets:\n",
    "                bot_strategy = infosets[k].get_average_strategy()\n",
    "            else:\n",
    "                bot_strategy = np.ones(len(valid_actions)) / len(valid_actions)\n",
    "\n",
    "            bot_move = sample_action(bot_strategy)\n",
    "            current_node = current_node.take_action(bot_move)\n",
    "\n",
    "            turn = \"RAND\"\n",
    "        else:\n",
    "            rand_strat = np.ones(len(valid_actions)) / len(valid_actions)\n",
    "            rand_move = sample_action(rand_strat)\n",
    "\n",
    "            current_node = current_node.take_action(rand_move)\n",
    "            turn = \"BOT\"\n",
    "\n",
    "wins = 0\n",
    "games = 10000\n",
    "\n",
    "for _ in range(games):\n",
    "    wins += play_against_random()\n",
    "\n",
    "print(f\"Win percentage: {wins / games * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your card is: 2 , Pot is 2\n"
     ]
    }
   ],
   "source": [
    "# Start the game.\n",
    "deck = list(range(3))\n",
    "random.shuffle(deck)\n",
    "player_card = deck[0]\n",
    "bot_card = deck[1]\n",
    "pot = 2\n",
    "\n",
    "history = []\n",
    "\n",
    "print(\"Your card is: {}\".format(player_card), \", Pot is\", pot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot did bet\n"
     ]
    }
   ],
   "source": [
    "my_action = BET\n",
    "history = history + [my_action]\n",
    "bot_strat = infosets[(1, bot_card, tuple(history))].get_average_strategy()\n",
    "bot_action = sample_action(bot_strat)\n",
    "history = history + [bot_action]\n",
    "\n",
    "print(\"Bot did\", \"check\" if bot_action == CHECK else \"bet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3052e4e95856f191c70944d34dc8a88b882e97c60324a0ab85812ea24714355"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
